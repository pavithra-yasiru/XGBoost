# XGBoost Classification Project

This repository contains an implementation of an **XGBoost classification model** using Python.  
The notebook walks through data preprocessing, training, and evaluating the XGBoost model on a dataset.

## 📌 Project Overview
The goal of this project is to demonstrate how to apply **Extreme Gradient Boosting (XGBoost)** for classification tasks.  
It includes steps such as dataset preparation, training, hyperparameter tuning, and evaluation.

## ⚙️ Steps in the Notebook
- Importing Libraries
- Loading Dataset
- Splitting Dataset into Train/Test
- Model Evaluation
- Training XGBoost Model

## 🛠️ Technologies Used
- Python 3
- Pandas & NumPy
- Scikit-learn
- Matplotlib & Seaborn (for visualization)
- XGBoost

## 🚀 How to Run
1. Clone this repository:
   ```bash
   git clone https://github.com/your-username/XGBoost-Classification.git
   cd XGBoost-Classification
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Open the Jupyter Notebook:
   ```bash
   jupyter notebook XGBoost.ipynb
   ```

## 📊 Results
- The notebook evaluates the performance of the model using **accuracy score, confusion matrix, and classification report**.

## 📂 Repository Structure
```
├── XGBoost.ipynb      # Jupyter notebook with code and explanations
├── README.md          # Project documentation
└── requirements.txt   # Python dependencies
```

## ✨ Author
Developed by Pavithra Yasiru.
